{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e741c4-bf73-4f95-8265-8e85ecf75e1f",
   "metadata": {},
   "source": [
    "## Langgraph Essay Writer Agent \n",
    "\n",
    "You are an expert writer tasked with writing a high level outline of an essay.  Write such an outline for user provided topic.  Give an outline of the essay along with notes and instructions for the sections\n",
    "\n",
    "##### Note: Go to JupyterLab terminal and execute following command before getting started\n",
    "<pre>\n",
    "    uv add langgraph\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316b0f92-e9cd-49d2-85fe-08a803e29513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': '### **Essay Outline: Understanding the Difference Between LangChain and LangSmith**\\n\\n---\\n\\n#### **I. Introduction**\\n- **Purpose**: Introduce the growing importance of large language models (LLMs) in AI development.\\n- **Thesis Statement**: While both LangChain and LangSmith are tools in the LangChain ecosystem, they serve distinct purposes: LangChain focuses on **application development** using LLMs, while LangSmith centers on **model training, testing, and deployment**.\\n- **Notes**: Highlight the need for clarity in understanding these tools, especially for developers and AI practitioners.\\n\\n---\\n\\n#### **II. Defining the Tools**\\n**A. LangChain**  \\n- **Definition**: A framework for building applications with LLMs, emphasizing **data integration**, **chainable workflows**, and **customizable logic**.  \\n- **Key Features**:  \\n  - **Chains**: Enables sequential processing of data (e.g., combining multiple models).  \\n  - **Prompts**: Templates for generating text from LLMs.  \\n  - **LLM Abstraction**: Supports multiple models (e.g., GPT-3, Llama).  \\n- **Use Cases**: Building chatbots, data pipelines, or analytics tools.  \\n\\n**B. LangSmith**  \\n- **Definition**: A platform for **training, testing, and deploying LLMs**, focusing on **model development**.  \\n- **Key Features**:  \\n  - **Model Training**: Tools for fine-tuning models on specific datasets.  \\n  - **Evaluation**: Metrics to assess model performance.  \\n  - **Deployment**: Simplifies integrating models into production.  \\n- **Use Cases**: Refining a model for a niche task (e.g., medical diagnostics) or optimizing a model’s accuracy.  \\n\\n**Notes**: Emphasize that LangSmith is part of the broader LangChain ecosystem but focuses on the **model lifecycle**, while LangChain is about **application architecture**.\\n\\n---\\n\\n#### **III. Key Differences**\\n**A. Focus Area**  \\n- **LangChain**: Application development (e.g., building a customer support chatbot).  \\n- **LangSmith**: Model training and optimization (e.g., improving a model’s accuracy for a specific task).  \\n\\n**B. Target Audience**  \\n- **LangChain**: Developers and engineers creating LLM-powered applications.  \\n- **LangSmith**: Data scientists and ML engineers refining models.  \\n\\n**C. Core Functionality**  \\n- **LangChain**: Manages **data flow** and **logic chains**.  \\n- **LangSmith**: Manages **model training**, **evaluation**, and **deployment**.  \\n\\n**D. Integration**  \\n- **LangChain** integrates with **LangSmith** for end-to-end workflows (e.g., training a model in LangSmith and deploying it via LangChain).  \\n\\n**Notes**: Use a table or bullet points to summarize the differences clearly.\\n\\n---\\n\\n#### **IV. Use Cases and Examples**\\n- **LangChain Example**:  \\n  - A company builds a customer support chatbot using LangChain’s chains and prompts to process user queries.  \\n- **LangSmith Example**:  \\n  - A team trains a custom LLM on medical data to diagnose patient symptoms, using LangSmith’s tools for evaluation and deployment.  \\n\\n**Notes**: Highlight scenarios where one tool is preferable (e.g., LangSmith for model development, LangChain for application logic).\\n\\n---\\n\\n#### **V. Conclusion**\\n- **Summary**: Reiterate that LangChain is for **application development**, while LangSmith is for **model training and deployment**.  \\n- **Importance**: Emphasize the complementary roles of both tools in the AI development lifecycle.  \\n- **Final Thought**: Encourage readers to choose the tool based on their specific needs (application vs. model development).\\n\\n---\\n\\n### **Instructions for Writing the Essay**\\n1. **Introduction**: Start with a hook about AI’s role in modern tech, then introduce the two tools.  \\n2. **Definitions**: Clearly explain each tool’s purpose, features, and target audience.  \\n3. **Key Differences**: Use subheadings (e.g., Focus Area, Target Audience) and include examples.  \\n4. **Use Cases**: Provide real-world scenarios to illustrate practical applications.  \\n5. **Conclusion**: Tie together the importance of both tools and their synergy.  \\n6. **Tone**: Maintain a professional yet accessible tone, avoiding overly technical jargon.  \\n\\nLet me know if you need a full draft or further clarification!'}}\n",
      "{'research_plan': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'LangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. 1. Limited Scalability: LangChain is not designed for large-scale production environments, making it less suitable for complex, high-traffic applications. 1. Comprehensive Platform: LangSmith offers a unified platform for managing all aspects of LLM development, making it ideal for large-scale, production-ready applications. LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities. ## Understanding LangChain Tools and Agents: A Guide to Building Smart AI Applications', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Jul 12, 2025 · Know the basic difference between Langchain tools LangChain : Your Toolkit for Building Complex LLM Applications What it does : LangChain is a foundational framework designed for developing applications powered by LLMs.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a **comprehensive platform** for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over **LangChain** and **LangSmith**, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.']}}\n",
      "{'generate': {'draft': '**The Difference Between LangChain and LangSmith**  \\n\\nThe rise of large language models (LLMs) has revolutionized artificial intelligence, enabling developers to create sophisticated applications that understand and generate human-like text. Amid this AI boom, tools like LangChain and LangSmith have emerged, each tailored to distinct aspects of AI development. While both are part of the broader LangChain ecosystem, their purposes diverge sharply: LangChain is a framework designed for building LLM-powered applications, whereas LangSmith is a platform focused on training, testing, and deploying models. Understanding this distinction is critical for developers and AI practitioners, as it clarifies when to prioritize application logic versus model refinement.  \\n\\nLangChain centers on *application development*, offering a modular framework to integrate LLMs into workflows. It emphasizes features like *chains*, which allow sequential processing of data (e.g., combining multiple models or steps), and *prompts*, which act as templates for generating text. Its abstraction layer supports diverse models, such as GPT-3 or Llama, making it ideal for tasks like chatbots, data pipelines, or analytics tools. In contrast, LangSmith is engineered for *model development*, providing tools to train, evaluate, and deploy LLMs. It includes functionalities like fine-tuning models on specialized datasets, measuring performance through metrics, and streamlining deployment. While LangChain manages how LLMs interact with users or systems, LangSmith focuses on optimizing the models themselves.  \\n\\nThe key differences between the two tools lie in their focus, audience, and functionality. LangChain caters to developers seeking to build applications, emphasizing data flow and customizable logic. LangSmith, on the other hand, targets data scientists and ML engineers refining models for specific tasks, such as medical diagnostics or customer service. Functionally, LangChain handles *application architecture*, while LangSmith manages *model lifecycle*—training, evaluation, and deployment. Notably, these tools complement each other: a team might use LangSmith to train a model and then integrate it into a LangChain-powered application for real-world use.  \\n\\nReal-world examples highlight their distinct roles. A company could use LangChain to develop a customer support chatbot, leveraging chains to process queries and prompts to generate responses. Meanwhile, a healthcare organization might employ LangSmith to fine-tune a model on patient data, ensuring accurate symptom analysis. In both cases, the choice of tool depends on the goal: LangChain for application logic and LangSmith for model optimization. These tools collectively bridge the gap between raw AI capabilities and practical implementation, empowering developers to tailor solutions to their needs.  \\n\\nIn conclusion, LangChain and LangSmith serve as twin pillars in the AI development ecosystem, each addressing a critical phase of the process. While LangChain enables the construction of LLM-driven applications, LangSmith ensures those models are accurate, efficient, and production-ready. Their synergy underscores the importance of choosing the right tool for the task at hand—whether the goal is to build an application or refine a model. As AI continues to evolve, these tools will remain essential for translating theoretical advancements into real-world impact.', 'revision_number': 2}}\n",
      "{'reflect': {'critique': '**Essay Critique and Recommendations**  \\n\\nYour essay provides a clear and structured overview of the differences between LangChain and LangSmith, effectively addressing their purposes, audiences, and use cases. Below are detailed recommendations to further strengthen your work:  \\n\\n---\\n\\n### **Strengths of the Essay**  \\n1. **Clear Organization**: The essay follows a logical flow, starting with an introduction, moving through technical distinctions, and concluding with real-world applications.  \\n2. **Relevant Examples**: The use of examples (e.g., customer support chatbots, healthcare applications) helps contextualize the tools’ roles.  \\n3. **Distinctive Focus**: You clearly separate LangChain’s application-centric design from LangSmith’s model-development focus, which is the essay’s strongest asset.  \\n\\n---\\n\\n### **Areas for Improvement**  \\n\\n#### **1. Depth of Technical Analysis**  \\nWhile the essay explains the tools’ purposes, it could delve deeper into **how** they function technically. For instance:  \\n- **LangChain**: Expand on *chains* and *prompts* with concrete examples (e.g., a chain that integrates a question-answering model with a database lookup).  \\n- **LangSmith**: Clarify concepts like *fine-tuning* (e.g., how hyperparameters or datasets influence model performance) or *metrics* (e.g., BLEU scores for evaluation).  \\n\\n**Recommendation**: Add 1–2 paragraphs with technical details, such as:  \\n- A step-by-step explanation of a chain in LangChain (e.g., “A chain might first process user input through a prompt template, then pass the output to a language model, and finally format the response”).  \\n- A description of LangSmith’s *model lifecycle* (e.g., “LangSmith allows users to track training iterations, compare models using metrics like accuracy or latency, and deploy optimized versions to production”).  \\n\\n---\\n\\n#### **2. Audience and Use Cases**  \\nThe essay mentions that LangChain targets developers and LangSmith targets data scientists, but it could benefit from **specific scenarios** to highlight these differences.  \\n\\n**Recommendation**:  \\n- **LangChain**: Describe a developer’s workflow (e.g., building a chatbot with LangChain’s chains to handle complex logic like user authentication or data retrieval).  \\n- **LangSmith**: Explain a data scientist’s process (e.g., using LangSmith to fine-tune a medical diagnostic model on a dataset of patient symptoms and outcomes).  \\n- **Cross-Tool Use**: Include a case study (e.g., “A team uses LangSmith to train a sentiment analysis model, then integrates it into a LangChain application for real-time customer feedback analysis”).  \\n\\n---\\n\\n#### **3. Depth of Comparison**  \\nThe essay distinguishes between the tools but could strengthen its analysis by explicitly addressing **trade-offs** and **interdependencies**.  \\n\\n**Recommendation**:  \\n- **When to Use Each**: Add a section comparing scenarios (e.g., “Use LangChain for applications requiring custom workflows, and LangSmith for models needing iterative refinement”).  \\n- **Ecosystem Synergy**: Highlight how the tools complement each other (e.g., “LangSmith’s model optimizations can be seamlessly integrated into LangChain applications, enabling scalable, production-ready solutions”).  \\n\\n---\\n\\n#### **4. Style and Clarity**  \\nThe essay is well-written, but some sentences could be tightened for clarity.  \\n\\n**Example**:  \\n- Original: *“LangChain centers on *application development*, offering a modular framework to integrate LLMs into workflows.”*  \\n- Suggestion: *“LangChain is designed for *application development*, providing a modular framework to integrate LLMs into workflows. Its key features include *chains* (for sequential processing) and *prompts* (for text generation).”*  \\n\\n**Recommendation**:  \\n- Break long sentences into shorter ones for readability.  \\n- Use bullet points or numbered lists for technical features (e.g., “LangChain’s key features include: 1. Chains for sequential processing… 2. Prompts as text-generation templates…”).  \\n\\n---\\n\\n#### **5. Length and Depth**  \\nThe essay is concise but could benefit from **expanded analysis** of the tools’ implications for AI development.  \\n\\n**Recommendation**:  \\n- Add a paragraph on the **broader impact** of these tools:  \\n  - How do they democratize AI development?  \\n  - What challenges remain (e.g., scalability, cost of training models in LangSmith)?  \\n  - How do they align with industry trends (e.g., MLOps, low-code platforms)?  \\n\\n---\\n\\n### **Final Suggestions**  \\n1. **Add 1–2 paragraphs of technical depth** on how each tool operates (e.g., chains, prompts, fine-tuning).  \\n2. **Incorporate specific use cases** to clarify audience needs.  \\n3. **Enhance comparisons** by addressing trade-offs and synergies.  \\n4. **Tighten prose** for clarity and flow.  \\n\\nBy expanding on these elements, your essay will offer a more comprehensive and nuanced analysis of LangChain and LangSmith. Keep up the excellent work! 🚀'}}\n",
      "{'research_critique': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'LangChain and LangSmith are two powerful tools developed by LangChain, a company focused on making it easier to build and deploy Large Language Model (LLM) applications. 1. Limited Scalability: LangChain is not designed for large-scale production environments, making it less suitable for complex, high-traffic applications. 1. Comprehensive Platform: LangSmith offers a unified platform for managing all aspects of LLM development, making it ideal for large-scale, production-ready applications. LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities. ## Understanding LangChain Tools and Agents: A Guide to Building Smart AI Applications', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Jul 12, 2025 · Know the basic difference between Langchain tools LangChain : Your Toolkit for Building Complex LLM Applications What it does : LangChain is a foundational framework designed for developing applications powered by LLMs.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', 'Compare LangChain, LangSmith, and Orq.ai to discover the best LLM development tools for building, deploying, and optimizing scalable AI applications. As a **comprehensive platform** for LLM product development, LangChain equips software teams with the tools needed to build, test, and deploy LLM-powered solutions at scale. While LangChain focuses on the flexibility and modularity required for building LLM-powered applications, LangSmith steps in to offer essential tools for deployment, monitoring, and optimization throughout the production process. Orq.ai offers several advantages over **LangChain** and **LangSmith**, providing a more integrated and efficient solution for LLM development. By offering an integrated solution that supports the entire LLM development lifecycle, Orq.ai enables teams to seamlessly build, deploy, and optimize LLM applications at scale, without needing to juggle multiple specialized tools.', 'This repository contains examples of using the LangChain framework to interact with Large Language Models (LLMs) for different prompt construction and execution techniques. Each script demonstrates a different approach for creating and using prompts with LLMs in Python, leveraging LangChain ’s utilities for managing prompts , output parsing, and chain execution.', 'It simplifies creating complex workflows that leverage natural language understanding, chaining multiple tasks, and integrating external tools like APIs and databases. LangChain helps developers harness the power of LLMs by offering components that facilitate chaining prompts, integrating external tools, and maintaining context. Whether you’re creating a chatbot, an intelligent assistant, or a text analysis tool, LangChain provides the building blocks to design complex workflows efficiently. from langchain.chains import SimpleSequentialChain chain1 = SimpleSequentialChain(llm=llm, prompt=template1) chain2 = SimpleSequentialChain(llm=llm, prompt=template2) output = final_chain.run(\"LangChain\") from langchain.agents import initialize_agent, Tool from langchain.tools import Tool from langchain.chains import ConversationChain from langchain.chains import RetrievalQA texts = [\"LangChain simplifies LLM workflows.\", \"LangChain supports tools and memory.\"] By leveraging components like prompt templates, chains, agents, tools, and memory, you can create sophisticated workflows tailored to various use cases.', 'February 17, 2025 - LangChain is a powerful framework designed to simplify and enhance the integration of large language models (LLMs) into various applications . It provides a structured way to work with prompts and chains, making it easier to build complex workflows with LLMs.', 'LangChain is the open, composable framework that provides a standard interface for every model, tool, and database – so you can build LLM apps that adapt as fast as the ecosystem evolves. ## Why use LangChain? How do I use LangChain with other products like LangSmith, LangGraph, or LangGraph Platform? LangChain provides a standard interface for connecting models, tools, and data, then integrates seamlessly with any of the Lang- family products. Use LangChain when you need fast integration and experimentation; use LangGraph when you need to build agents that can reliably handle complex tasks. Should I start with LangChain or LangGraph for building agents? Use **LangChain** for **composability and model flexibility**— great for quickly chaining LLMs with tools, retrievers, and external data sources.', 'LangChain 🦜️🔗 中文网，跟着LangChain一起学LLM/GPT开发JS/TS Langchain JS/TS Langchain (opens in a new tab)Python Langchain Python Langchain (opens in a new tab)OpenAI 中文文档 OpenAI 中文文档 (opens in a new tab) GitHub (opens in a new tab) *   JS/TS Langchain (opens in a new tab) *   Python Langchain (opens in a new tab) *   OpenAI 中文文档 (opens in a new tab) *   Pinecone 中文文档 (opens in a new tab) *   Milvus 中文文档 (opens in a new tab) LangSmith (opens in a new tab) 帮助您跟踪和评估您的语言模型应用程序和智能代理，以帮助您从原型过渡到生产。 有关更多信息，请参阅LangSmith 文档 (opens in a new tab)。 要了解如何集成 LangSmith 到您的工作流程中，以及演示端到端示例，请查看LangSmith Cookbook (opens in a new tab)。其中一些指南包括： *   在 JS 应用程序中利用用户反馈 (链接 (opens in a new tab)) *   构建自动化反馈流水线 (链接 (opens in a new tab)) *   如何使用真实使用数据对 LLM 进行微调 (链接 (opens in a new tab))', '**LangChain、LangGraph 和 LangSmith 正在发展壮大并招聘多个职位。加入我们的团队！** # LangSmith 入门 **LangSmith** 是一个用于构建生产级 LLM 应用程序的平台。它能让您密切监控和评估您的应用程序，从而帮助您快速、自信地交付产品。 ### 可观测性 在 LangSmith 中分析跟踪，并基于此配置指标、仪表板和警报。 ### 评估 根据生产流量评估您的应用程序 — 衡量应用程序性能并获取您数据的人工反馈。 ### 提示工程 迭代提示，并支持自动版本控制和协作功能。 LangSmith + LangChain 开源版 LangSmith 是与框架无关的 — 它可以与 LangChain 的开源框架 `langchain` 和 `langgraph` 一起使用，也可以单独使用。 如果您正在使用其中任何一个，您可以通过一个环境变量启用 LangSmith 跟踪。更多信息请参阅使用 LangChain 设置 LangSmith 或 使用 LangGraph 设置 LangSmith 的操作指南。 ## 可观测性\\u200b 可观测性对于任何软件应用程序都至关重要，尤其是对于 LLM 应用程序。LLM 本身是非确定性的，这意味着它们可能会产生意想不到的结果。这使得它们比一般的应用程序更难调试。 这正是 LangSmith 可以提供帮助的地方！LangSmith 拥有 LLM 原生的可观测性，让您能够从应用程序中获得有意义的洞察。LangSmith 的可观测性功能涵盖了应用程序开发的所有阶段——从原型设计、内测到生产。 * 首先，为您的应用程序添加跟踪。 * 创建仪表板以查看 RPS、错误率和成本等关键指标。 ## 评估\\u200b AI 应用程序的质量和开发速度取决于高质量的评估数据集和指标，以便对应用程序进行测试和优化。LangSmith SDK 和 UI 使构建和运行高质量评估变得容易。 * 首先，创建您的第一个评估。 * 使用我们现成的评估器作为起点，快速评估您的应用程序性能。 * 在 LangSmith UI 中分析评估结果，并比较随时间变化的结果。 * 轻松收集关于您数据的人工反馈，以改进您的应用程序。 ## 提示工程\\u200b 传统软件应用程序通过编写代码来构建，而 AI 应用程序则涉及编写提示来指导 LLM 执行操作。LangSmith 提供了一套工具，旨在支持和促进提示工程，帮助您为应用程序找到完美的提示。 * 首先，创建您的第一个提示。 * 使用操场（Playground）迭代模型和提示。 * 在您的应用程序中以编程方式管理提示。 #### 此页面有帮助吗？ #### 您可以留下详细反馈 在 GitHub 上. * 可观测性 * 评估 * 提示工程', 'June 25, 2025 - LLM Evaluation : Practical insights on metrics , frameworks, tools, challenges, and best practices for robust AI performance.', '* Understand the importance of observability in LLM applications and how to implement it using LangSmith for real-time monitoring and debugging. LangSmith is a state-of-the-art testing framework designed for the evaluation of language models and AI applications, with a particular emphasis on creating production-grade LLM applications. Setting LANGCHAIN\\\\_TRACING\\\\_V2 to true enables tracing (logging), which is essential for debugging LLMs. Once you run the create\\\\_project command successfully, you will see the project listed in the Projects section of the LangSmith web UI. This code snippet demonstrates AI-assisted feedback, where an LLM (GPT-3.5-turbo) scores each run’s input based on several metrics (relevance, difficulty, verbosity, and specificity). By utilizing LangSmith’s monitoring, evaluation, debugging, testing, tracing, and observability functions, developers and businesses can significantly improve their model’s performance and reliability.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.', '* LangChain: The Foundation of AI Application Development The LangChain ecosystem has grown into a powerful toolkit for building, managing, and scaling AI applications. ## LangChain: The Foundation of AI Application Development LangGraph is the next step in building powerful AI workflows. With its drag-and-drop interface, you can design advanced AI workflows without writing much code, perfect for both developers and non-technical users. LangSmith is the observability and evaluation platform for AI applications--whether built with LangChain or not. It helps teams monitor, debug, test, and optimize LLM-based systems with deep visibility into how your AI behaves in real-world scenarios. At Techvoot, we help startups and enterprises design, develop, and optimize custom LLM solutions using LangChain and the broader AI ecosystem.', '* LangChain: The Foundation of AI Application Development The LangChain ecosystem has grown into a powerful toolkit for building, managing, and scaling AI applications. ## LangChain: The Foundation of AI Application Development LangGraph is the next step in building powerful AI workflows. With its drag-and-drop interface, you can design advanced AI workflows without writing much code, perfect for both developers and non-technical users. LangSmith is the observability and evaluation platform for AI applications--whether built with LangChain or not. It helps teams monitor, debug, test, and optimize LLM-based systems with deep visibility into how your AI behaves in real-world scenarios. At Techvoot, we help startups and enterprises design, develop, and optimize custom LLM solutions using LangChain and the broader AI ecosystem.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. | Key Features | Modular chains and sequences, prompt templates, agent framework, data connectors, wide model support, community integrations. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation.']}}\n",
      "{'generate': {'draft': '**The Difference Between LangChain and LangSmith**  \\n\\nThe rapid evolution of large language models (LLMs) has transformed artificial intelligence, enabling innovations across industries. As developers and researchers seek tools to harness these models, distinctions between platforms like **LangChain** and **LangSmith** become critical. While both tools belong to the broader LangChain ecosystem, their purposes diverge sharply: **LangChain** is designed for **building applications** with LLMs, whereas **LangSmith** focuses on **training, testing, and deploying models**. Understanding this distinction is vital for professionals aiming to optimize AI workflows.  \\n\\n**LangChain** serves as a framework for developers seeking to integrate LLMs into real-world applications. It emphasizes **data flow** and **customizable logic** through features like *chains* (which allow sequential processing of tasks), *prompts* (templates for generating text), and *LLM abstraction* (supporting multiple models). For example, a developer might use LangChain to create a chatbot that processes user inputs, consults a knowledge base, and generates responses. Its strength lies in enabling complex applications, such as analytics tools or customer service platforms, by abstracting the intricacies of model interactions. In contrast, **LangSmith** is tailored for **model development**, offering tools to train, evaluate, and deploy LLMs. It provides functionalities like *fine-tuning models on specific datasets*, *evaluating performance metrics*, and *streamlining deployment*. A medical AI team, for instance, might use LangSmith to refine a model’s accuracy in diagnosing patient symptoms.  \\n\\nThe core difference between the two lies in their **focus areas** and **audiences**. **LangChain** caters to **developers and engineers** who prioritize application logic, such as integrating LLMs into workflows or optimizing user interactions. **LangSmith**, on the other hand, targets **data scientists and ML engineers** focused on model refinement. While LangChain manages data processing and logic chains, LangSmith handles the *model lifecycle*, from training to production. Their complementary roles are evident in workflows: a team might train a model in LangSmith and then deploy it via LangChain, creating a seamless pipeline.  \\n\\nReal-world applications highlight their unique strengths. **LangChain** excels in scenarios requiring *application architecture*, such as building a virtual assistant that aggregates data from multiple sources. **LangSmith** shines in *model-centric tasks*, like enhancing a fraud detection system by fine-tuning a model on transactional data. For instance, a startup developing a legal research tool might use LangChain to structure queries and analyze case law, while a healthcare organization could rely on LangSmith to train a model for interpreting medical scans. These examples underscore how each tool addresses distinct challenges.  \\n\\nIn conclusion, **LangChain** and **LangSmith** are not interchangeable but complementary. **LangChain** is the backbone of application development, offering flexibility for integrating LLMs into complex systems. **LangSmith** is the cornerstone of model development, empowering users to train and optimize AI models. Together, they form a cohesive ecosystem, enabling professionals to innovate at both the application and model levels. By choosing the right tool—**application development** versus **model training**—developers can unlock the full potential of LLMs, driving progress in AI.', 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "#set up your-tavily-key\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from langchain_core.tools import Tool\n",
    "from pydantic import BaseModel, ValidationError\n",
    "#from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain.tools import tool\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from tavily import TavilyClient\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from IPython.display import Image\n",
    "import re\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "from cfenv import AppEnv\n",
    "\n",
    "\n",
    "# connect to tavily search tool - use your tavily api key\n",
    "os.environ['TAVILY_API_KEY']=\"your_tavily_key\"\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "#tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "#define agent state\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    lnode: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    queries: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    count: Annotated[int, operator.add]\n",
    "\n",
    "\n",
    "#define and configure the model\n",
    "# Load CF environment\n",
    "env = AppEnv()\n",
    "# configure model\n",
    "httpx_client = httpx.Client(http2=True, verify=False, timeout=10.0)\n",
    "# Get bound service \"gen-ai-qwen3-ultra\"\n",
    "chat_service = env.get_service(name=\"gen-ai-qwen3-ultra\")\n",
    "chat_credentials = chat_service.credentials\n",
    "\n",
    "# Initialize LLM with credentials from cfenv\n",
    "model = ChatOpenAI(\n",
    "    temperature=0.9,\n",
    "    model=chat_credentials[\"model_name\"],\n",
    "    base_url=chat_credentials[\"api_base\"],\n",
    "    api_key=chat_credentials[\"api_key\"],\n",
    "    http_client=httpx_client\n",
    ")\n",
    "\n",
    "#define prompts\n",
    "PLAN_PROMPT = \"\"\"\n",
    "You are an expert writer tasked with writing a high level outline of an eassy. \\\n",
    "Write such an outline for the user provided topic. Give an outline of eassy along \\\n",
    "with any relevant notes or instructions for the sections.\n",
    "\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"\n",
    "You are an eassy assistant tasked with writing excellent 5-paragraph eassys. \\\n",
    "Generate the best eassy possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of ypur previous attempts. \\\n",
    "\n",
    "--------\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"\n",
    "You are a teacher grading an eassy submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\n",
    "\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"\n",
    "You are a researcher charged with providing information that can \\\n",
    "be used when writing the following eassy. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max\n",
    "\"\"\"\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"\n",
    "You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as oulined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. \\\n",
    "Only generate 3 queries max.\n",
    "\"\"\"\n",
    "    \n",
    "def extract_json(text):\n",
    "    # Remove unwanted tags like <think> and <speak>\n",
    "    cleaned_text = re.sub(r'<\\/?[\\w\\d]+>', '', text).strip()\n",
    "\n",
    "    # Now try to extract the JSON part using regex\n",
    "    match = re.search(r'\\{.*\\}', cleaned_text, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"No JSON object found in response\")\n",
    "    return json.loads(match.group(0))\n",
    "\n",
    "def normalize_to_queries(output: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Normalize LLM output into a dict matching the Queries schema.\n",
    "    Always returns: {\"queries\": [...]}.\n",
    "    Also logs the result as clean JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove <think>...</think> blocks if present\n",
    "    output = re.sub(r\"<think>.*?</think>\", \"\", output, flags=re.DOTALL).strip()\n",
    "\n",
    "    data: Dict[str, Any]\n",
    "\n",
    "    # Try strict JSON parse first\n",
    "    try:\n",
    "        parsed = json.loads(output)\n",
    "        if isinstance(parsed, dict) and \"queries\" in parsed:\n",
    "            data = parsed\n",
    "        elif isinstance(parsed, list):\n",
    "            data = {\"queries\": parsed}\n",
    "        else:\n",
    "            raise ValueError(\"Invalid schema\")\n",
    "    except Exception:\n",
    "        # Fallback: treat as markdown/bullet/numbered list\n",
    "        lines = [\n",
    "            re.sub(r'^\\s*[\\d\\-\\*\\.\\)]*\\s*', '', line).strip(' *\"`')\n",
    "            for line in output.splitlines() if line.strip()\n",
    "        ]\n",
    "        # Deduplicate while preserving order\n",
    "        seen = set()\n",
    "        unique_lines = [q for q in lines if not (q in seen or seen.add(q))]\n",
    "        data = {\"queries\": unique_lines}\n",
    "\n",
    "    return data\n",
    "    \n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]\n",
    "\n",
    "#implement nodes\n",
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT),\n",
    "        HumanMessage(content=state[\"task\"])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    response_content = response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "    # Remove <think>...</think> blocks completely\n",
    "    response_content = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "    return {\"plan\": response_content}\n",
    "    \n",
    "def research_plan_node(state: dict):\n",
    "    \"\"\"\n",
    "    Generates a research plan using a Qwen model and Tavily search.\n",
    "    Works without Pydantic.\n",
    "    \"\"\"\n",
    "    # Invoke Qwen model (plain text output)\n",
    "    raw_response = model.invoke(\n",
    "        [\n",
    "            SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "            HumanMessage(content=state[\"task\"]),\n",
    "        ]\n",
    "    )\n",
    "    response_content = getattr(raw_response, \"content\", str(raw_response))\n",
    "\n",
    "    # Remove <think>...</think> if present\n",
    "    response_content = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Normalize into a list of queries (handle bullets, numbers, etc.)\n",
    "    lines = [\n",
    "        re.sub(r'^\\s*[\\d\\-\\*\\.\\)]*\\s*', '', line).strip(' *\"`')\n",
    "        for line in response_content.splitlines()\n",
    "        if line.strip()\n",
    "    ]\n",
    "    # Deduplicate\n",
    "    seen = set()\n",
    "    queries_list = [q for q in lines if not (q in seen or seen.add(q))]\n",
    "\n",
    "    # Initialize content\n",
    "    content = state.get(\"content\", [])\n",
    "\n",
    "    # Perform Tavily searches\n",
    "    for q in queries_list:\n",
    "        try:\n",
    "            response = tavily.search(query=q, max_results=2)\n",
    "            for r in response.get(\"results\", []):\n",
    "                content_piece = r.get(\"content\", \"\")\n",
    "                if content_piece:\n",
    "                    content.append(str(content_piece))\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed for query '{q}': {e}\")\n",
    "\n",
    "    return {\n",
    "        \"content\": content,\n",
    "    }\n",
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join([\"content\"] or [])\n",
    "    user_message = HumanMessage(content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
    "        user_message,\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    response_content = response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "    # Remove <think>...</think> blocks completely\n",
    "    response_content = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "    return {\n",
    "        \"draft\": response_content,\n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1,\n",
    "    }\n",
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state['draft']),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    response_content = response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "    # Remove <think>...</think> blocks completely\n",
    "    response_content = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "\n",
    "    return {\"critique\": response_content}\n",
    "\n",
    "def research_critique_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Generates a research plan using a Qwen model and Tavily search.\n",
    "    Works without Pydantic.\n",
    "    \"\"\"\n",
    "    # Invoke Qwen model (plain text output)\n",
    "    raw_response = model.invoke(\n",
    "        [\n",
    "            SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "            HumanMessage(content=state[\"critique\"]),\n",
    "        ]\n",
    "    )\n",
    "    response_content = getattr(raw_response, \"content\", str(raw_response))\n",
    "\n",
    "    # Remove <think>...</think> if present\n",
    "    response_content = re.sub(r\"<think>.*?</think>\", \"\", response_content, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Normalize into a list of queries (handle bullets, numbers, etc.)\n",
    "    lines = [\n",
    "        re.sub(r'^\\s*[\\d\\-\\*\\.\\)]*\\s*', '', line).strip(' *\"`')\n",
    "        for line in response_content.splitlines()\n",
    "        if line.strip()\n",
    "    ]\n",
    "    # Deduplicate\n",
    "    seen = set()\n",
    "    queries_list = [q for q in lines if not (q in seen or seen.add(q))]\n",
    "\n",
    "    # Initialize content\n",
    "    content = state.get(\"content\", [])\n",
    "\n",
    "    # Perform Tavily searches\n",
    "    for q in queries_list:\n",
    "        try:\n",
    "            response = tavily.search(query=q, max_results=2)\n",
    "            for r in response.get(\"results\", []):\n",
    "                content_piece = r.get(\"content\", \"\")\n",
    "                if content_piece:\n",
    "                    content.append(str(content_piece))\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed for query '{q}': {e}\")\n",
    "\n",
    "    return {\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\"\n",
    "\n",
    "\n",
    "#build graph\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)\n",
    "\n",
    "#set entry point\n",
    "builder.set_entry_point(\"planner\")\n",
    "\n",
    "#define conditional edges\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n",
    "\n",
    "#define edges\n",
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")\n",
    "\n",
    "\n",
    "\n",
    "#print graph\n",
    "#Image(graph.get_graph().draw_png())\n",
    "\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "    for s in graph.stream({\n",
    "        'task': \"what is the difference between langchain and langsmith\",\n",
    "        \"max_revisions\": 2,\n",
    "        \"revision_number\": 1,\n",
    "    }, thread):\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba91136-e012-4996-aa8e-409a3f70bd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* Running on public URL: https://9c1fb780e711e9f802.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9c1fb780e711e9f802.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helper import ewriter, writer_gui\n",
    "MultiAgent = ewriter()\n",
    "app = writer_gui(MultiAgent.graph)\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572a74a3-9c14-41a5-9131-80bd7064f444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     +-----------+                  \n",
      "                     | __start__ |                  \n",
      "                     +-----------+                  \n",
      "                            *                       \n",
      "                            *                       \n",
      "                            *                       \n",
      "                      +---------+                   \n",
      "                      | planner |                   \n",
      "                      +---------+                   \n",
      "                            *                       \n",
      "                            *                       \n",
      "                            *                       \n",
      "                   +---------------+                \n",
      "                   | research_plan |                \n",
      "                   +---------------+                \n",
      "                            *                       \n",
      "                            *                       \n",
      "                            *                       \n",
      "                      +----------+                  \n",
      "                      | generate |                  \n",
      "                   ...+----------+***               \n",
      "               ....         .        ****           \n",
      "           ....             .            ****       \n",
      "         ..                 .                ****   \n",
      "+---------+           +---------+                ** \n",
      "| __end__ |           | reflect |               **  \n",
      "+---------+           +---------+             **    \n",
      "                                ***         **      \n",
      "                                   *      **        \n",
      "                                    **   *          \n",
      "                            +-------------------+   \n",
      "                            | research_critique |   \n",
      "                            +-------------------+   \n"
     ]
    }
   ],
   "source": [
    "app.graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209d405-e9cf-427f-9ecc-99afc88c1815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
