{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829a7904-7c41-4d9d-b09c-6995dba6ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6435162c-48c1-423e-89bd-dd0dd0a6d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mock_pdf_files(directory):\n",
    "    \"\"\"Creates 5 mock PDF files based on aircraft claims data using pandas and reportlab.\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    print(f\"Created directory: {directory}\")\n",
    "\n",
    "    # 1. Create DataFrame using pandas\n",
    "    data = {\n",
    "        'Claim_ID': ['C2024-101', 'C2024-102', 'C2024-103', 'C2024-104', 'C2024-105'],\n",
    "        'Aircraft_Model': ['Boeing 737', 'Airbus A320', 'Cessna 172', 'Embraer 175', 'DHC-8 Q400'],\n",
    "        'Damage_Cause': ['Hard Landing', 'FOD Ingestion', 'Hail Damage', 'Bird Strike', 'Tail Strike'],\n",
    "        'Claim_Value': ['$150,000', '$4,500,000', '$25,000', '$350,000', '$900,000'],\n",
    "        'Description': [\n",
    "            'Minor flap damage during a hard landing in strong crosswinds. Total claim value: $150,000.',\n",
    "            'Engine compressor stall due to foreign object debris (FOD) ingestion on the runway. Claim amount: $4,500,000.',\n",
    "            'Hail damage to the wing surface during an unexpected storm. Simple repair. Claim value: $25,000.',\n",
    "            'Damage to the nose cone and radome after hitting a flock of birds on final approach. Claim amount: $350,000.',\n",
    "            'Minor structural damage to the fuselage near the rear pressure bulkhead during landing. Claim amount: $900,000.'\n",
    "        ]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    # 2. Iterate and create a PDF for each claim\n",
    "    for index, row in df.iterrows():\n",
    "        filename = f\"{directory}/{row['Claim_ID']}.pdf\"\n",
    "        doc = SimpleDocTemplate(filename, pagesize=letter)\n",
    "\n",
    "        story = []\n",
    "        # Title and basic info\n",
    "        story.append(Paragraph(f\"<b>AIRCRAFT CLAIMS REPORT: {row['Claim_ID']}</b>\", styles['Title']))\n",
    "        story.append(Paragraph(\"<br/>\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"<b>Aircraft Model:</b> {row['Aircraft_Model']}\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"<b>Primary Cause:</b> {row['Damage_Cause']}\", styles['Normal']))\n",
    "        story.append(Paragraph(f\"<b>Claim Value:</b> {row['Claim_Value']}\", styles['Normal']))\n",
    "        story.append(Paragraph(\"<br/>\", styles['Normal']))\n",
    "        # Detailed Description\n",
    "        story.append(Paragraph(\"<b>Damage Description:</b>\", styles['Normal']))\n",
    "        story.append(Paragraph(row['Description'], styles['Normal']))\n",
    "\n",
    "        doc.build(story)\n",
    "\n",
    "    print(f\"✅ Created {len(df)} structured PDF claim files in {directory}.\")\n",
    "    # Return a list of created files\n",
    "    return [f\"{directory}/{cid}.pdf\" for cid in df['Claim_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516dcc12-61d1-4c07-aae6-ba7e296a9d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ./aircraft_claims_pdfs\n",
      "✅ Created 5 structured PDF claim files in ./aircraft_claims_pdfs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./aircraft_claims_pdfs/C2024-101.pdf',\n",
       " './aircraft_claims_pdfs/C2024-102.pdf',\n",
       " './aircraft_claims_pdfs/C2024-103.pdf',\n",
       " './aircraft_claims_pdfs/C2024-104.pdf',\n",
       " './aircraft_claims_pdfs/C2024-105.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF_DIR = \"./aircraft_claims_pdfs\"\n",
    "create_mock_pdf_files(PDF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c760cefa-a997-497b-a47c-27df2af2b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vcap/app/cf-jupyterlab-workshop\n"
     ]
    }
   ],
   "source": [
    "# set the working directory for the project\n",
    "%cd /home/vcap/app/cf-jupyterlab-workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3fb2c2-d2ba-44e0-8f1d-ea632e17b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- nomic-embed-text-v1025 (capabilities: EMBEDDING)\n",
      "Embedding model: nomic-embed-text-v1025\n"
     ]
    }
   ],
   "source": [
    "## Ingestion pipeline to load data\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import httpx\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from cfenv import AppEnv\n",
    "import sys, os\n",
    "import warnings\n",
    "from tanzu_utils import CFGenAIService\n",
    "warnings.filterwarnings('ignore')\n",
    "# -----------------------------\n",
    "# Load services from env\n",
    "# -----------------------------\n",
    "env = AppEnv()\n",
    "\n",
    "# -----------------------------\n",
    "# Embedding service details\n",
    "# -----------------------------\n",
    "embedding_service = CFGenAIService(\"tanzu-nomic-embed-text\")\n",
    "\n",
    "# List available models\n",
    "embedding_models = embedding_service.list_models()\n",
    "for m in embedding_models:\n",
    "    print(f\"- {m['name']} (capabilities: {', '.join(m['capabilities'])})\")\n",
    "\n",
    "\n",
    "api_base = embedding_service.api_base + \"/openai/v1\"\n",
    "api_key = embedding_service.api_key\n",
    "model_name = embedding_models[0][\"name\"]\n",
    "\n",
    "print(\"Embedding model:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68771f3a-ac24-4c97-ab58-98e75478fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB URI: postgresql://pgadmin:629PVy514m0w8rc3jq7Y@q-s0.postgres-instance.kdc01-dvs-lab-mgt-net-82.service-instance-465d60d4-e494-49a5-aace-022e92fbdc1c.bosh:5432/postgres\n",
      "Connected to: PostgreSQL 16.6 (VMware Postgres 16.6.0) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, 64-bit\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Database connection\n",
    "# -----------------------------\n",
    "db_service = env.get_service(name=\"vector-db\")\n",
    "db_credentials = db_service.credentials\n",
    "db_uri = db_credentials[\"uri\"]\n",
    "\n",
    "print(\"DB URI:\", db_uri)\n",
    "\n",
    "engine = create_engine(db_uri)\n",
    "\n",
    "# Test DB connection\n",
    "with engine.connect() as conn:\n",
    "    version = conn.execute(text(\"SELECT version();\")).fetchone()\n",
    "    print(\"Connected to:\", version[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb0a4f1-5953-4083-aaf0-02e9e87fa08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:00<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 document pages/chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PDF_DIR = \"/home/vcap/app/cf-jupyterlab-workshop/RAGPDF/aircraft_claims_pdfs\"\n",
    "loader = DirectoryLoader(\n",
    "            path=PDF_DIR,\n",
    "            glob=\"**/*.pdf\", \n",
    "            loader_cls=PyPDFLoader,\n",
    "            show_progress=True\n",
    "        )\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} document pages/chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf97ba1-d87f-4cbb-bce7-70cb123ac2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split documents into 5 text chunks.\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Split Documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Split documents into {len(splits)} text chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161bb422-4d84-4338-90ae-0264c0b3f58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name cmetadata                                  uuid\n",
      "0     my_documents_collection      None  c202026b-4755-4e63-b4c0-f9856fdcfd01\n",
      "1               aircraft_docs      None  e1e375c2-4585-4b26-9e52-39fbde99407c\n",
      "2       finsmart-transactions      None  4336d726-23f9-41e0-b828-e0cb64ca01c5\n",
      "3    maintenance_and_taxonomy      None  5088ed6d-678b-4f75-b2e6-84dbc31df561\n",
      "4  aircraft_claims_collection      None  b6e63f4a-65f0-43ea-99b2-b97d1399bfc6\n",
      "                                     id                         collection_id  \\\n",
      "0  04d1a97d-17d2-4c9e-98b6-af9fb772d7ef  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "1  69b105d6-d6f5-4044-be00-4e079a7acf8d  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "2  de890765-3f45-469e-aafa-b708891d1cd8  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "3  f218d4ff-4d02-44f7-a164-0a9673f8fa06  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "4  3e2084a9-2576-4a3c-9a68-7da42545eaf6  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "5  9ea8589d-28a9-4d1a-b165-a4a7287a6720  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "6  ea8406ed-cc29-45ff-a51f-6fc62ae93b0e  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "7  920d351a-ed45-49b7-9691-4d94b8eaff8a  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "8  74766774-49a6-47a1-a17e-73243c921076  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "9  aa59039d-6dd8-482d-9d27-b94ed4ca348a  4336d726-23f9-41e0-b828-e0cb64ca01c5   \n",
      "\n",
      "                                           embedding  \\\n",
      "0  [0.0479077,0.045045864,-0.16075699,-0.01206880...   \n",
      "1  [0.04664518,0.06340752,-0.14157858,-0.03608614...   \n",
      "2  [0.028759459,0.032215536,-0.15348996,-0.040423...   \n",
      "3  [0.039098296,0.036239512,-0.18852635,-0.033668...   \n",
      "4  [0.028691323,0.05545073,-0.17014895,-0.0225148...   \n",
      "5  [0.015750354,0.07791306,-0.1656343,-0.02517879...   \n",
      "6  [-0.009984627,0.0076993047,-0.20070979,-0.0060...   \n",
      "7  [0.039288383,0.018775815,-0.18041416,-0.036793...   \n",
      "8  [-0.002921887,0.022742782,-0.17877021,-0.00921...   \n",
      "9  [-0.0054819826,0.06920945,-0.17897059,-0.06860...   \n",
      "\n",
      "                                            document  \\\n",
      "0  Transaction T001 (Deposit): Paycheck deposit f...   \n",
      "1  Transaction T002 (Investment): Purchased 10 sh...   \n",
      "2  Transaction T003 (Expense): Rent payment of $-...   \n",
      "3  Transaction T004 (Dividend): Dividend from VTI...   \n",
      "4  Transaction T005 (Expense): Grocery shopping o...   \n",
      "5  Portfolio P001 holding 25 shares of Apple Inc....   \n",
      "6  Portfolio P002 holding 40 shares of Vanguard T...   \n",
      "7  Portfolio P003 holding 15 shares of Microsoft ...   \n",
      "8  Portfolio P004 holding 5 shares of Tesla Inc. ...   \n",
      "9  Portfolio P005 holding 10 shares of Alphabet I...   \n",
      "\n",
      "                                           cmetadata  \n",
      "0  {'id': 'T001', 'source': 'transactions.csv', '...  \n",
      "1  {'id': 'T002', 'source': 'transactions.csv', '...  \n",
      "2  {'id': 'T003', 'source': 'transactions.csv', '...  \n",
      "3  {'id': 'T004', 'source': 'transactions.csv', '...  \n",
      "4  {'id': 'T005', 'source': 'transactions.csv', '...  \n",
      "5  {'id': 'P001', 'source': 'portfolio.csv', 'use...  \n",
      "6  {'id': 'P002', 'source': 'portfolio.csv', 'use...  \n",
      "7  {'id': 'P003', 'source': 'portfolio.csv', 'use...  \n",
      "8  {'id': 'P004', 'source': 'portfolio.csv', 'use...  \n",
      "9  {'id': 'P005', 'source': 'portfolio.csv', 'use...  \n",
      "Ingestion complete. Data stored in PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Embedding function (REST call)\n",
    "# -----------------------------\n",
    "url = api_base + \"/embeddings\"\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n",
    "COLLECTION_NAME = \"aircraft_claims_collection\"\n",
    "def embed_text(text: str):\n",
    "    payload = {\"model\": model_name, \"input\": text}\n",
    "    resp = requests.post(url, headers=headers, json=payload, verify=False)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"data\"][0][\"embedding\"]\n",
    "\n",
    "class CustomEmbeddings:\n",
    "    def embed_documents(self, texts): return [embed_text(t) for t in texts]\n",
    "    def embed_query(self, text): return embed_text(text)\n",
    "\n",
    "embedding = CustomEmbeddings()\n",
    "\n",
    "# -----------------------------\n",
    "# PGVector setup\n",
    "# -----------------------------\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embedding,\n",
    "    connection=db_uri,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    use_jsonb=True,\n",
    "    create_extension=True,       # will create pgvector extension if not exists\n",
    "    pre_delete_collection=True,  # clears old data on restart\n",
    ")\n",
    "\n",
    "\n",
    "vectorstore.add_documents(splits)\n",
    "query = text(\"SELECT * FROM langchain_pg_collection LIMIT 10;\")\n",
    "print(pd.read_sql(query, engine))\n",
    "\n",
    "query2 = text(\"SELECT * FROM langchain_pg_embedding LIMIT 10;\")\n",
    "print(pd.read_sql(query2, engine))\n",
    "print(\"Ingestion complete. Data stored in PostgreSQL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8dbd4fe-886d-45d8-b244-455f302e7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- openai/gpt-oss-120b (capabilities: CHAT, TOOLS)\n",
      "chat model: nomic-embed-text-v1025https://genai-proxy.sys.tas-ndc.kuhn-labs.com/tanzu-nomic-embed-text-v1025-4201d1d/openai/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from datetime import date\n",
    "import warnings\n",
    "import ssl\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from openai import OpenAI\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "# Optional: configure custom http client\n",
    "httpx_client = httpx.Client(http2=True, verify=False, timeout=30.0)\n",
    "# -----------------------------\n",
    "# cat service details\n",
    "# -----------------------------\n",
    "chat_service = CFGenAIService(\"tanzu-gpt-oss-120b\")\n",
    "\n",
    "# List available models\n",
    "chat_models = chat_service.list_models()\n",
    "for m in chat_models:\n",
    "    print(f\"- {m['name']} (capabilities: {', '.join(m['capabilities'])})\")\n",
    "\n",
    "\n",
    "chat_api_base = chat_service.api_base + \"/openai/v1\"\n",
    "chat_api_key = chat_service.api_key\n",
    "chat_model_name = chat_models[0][\"name\"]\n",
    "\n",
    "print(\"chat model:\", model_name + api_base)\n",
    "\n",
    "# Initialize LLM with credentials from cfenv\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.9,\n",
    "    model=chat_model_name,\n",
    "    base_url=chat_api_base,\n",
    "    api_key=chat_api_key,\n",
    "    http_client=httpx_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a32cf1e5-6d94-4930-af4e-bb6138272409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vcap/tmp/ipykernel_5017/1409757478.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain-classic 0.1.0 and will be removed in 1.0. Use `invoke` instead.\n",
      "  result = qa.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Primary Cause of Damage:** FOD (Foreign Object Debris) ingestion  \n",
      "**Claim Value:** $4,500,000\n"
     ]
    }
   ],
   "source": [
    "# Create a retriever from your vectorstore\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "\n",
    "# Build a RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "query = \"What was the primary cause of damage and the value for the claim involving the Airbus A320?\"\n",
    "result = qa.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d791b68-4572-48ec-9595-b5cb15c5cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total sum of all claim values is **$1,400,000**.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "query = \"What is the total sum of all claim values in the database?\"\n",
    "result = qa.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "310e6abd-58d1-4ded-8908-1ef55b2f2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Hail Damage Incident Summary**\n",
      "\n",
      "| Claim ID | Aircraft Model | Primary Cause | Claim Value | Damage Description |\n",
      "|----------|----------------|---------------|------------|--------------------|\n",
      "| C2024-103 | Cessna 172 | Hail Damage | $25,000 | Hail struck the wing surface during an unexpected storm, requiring a simple repair. |\n",
      "\n",
      "*No other hail‑related claims are present in the provided data.*\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "query = \"Summarize all hail damage incidents.\"\n",
    "result = qa.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4540d44-3820-47c8-909c-d117c531f1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
