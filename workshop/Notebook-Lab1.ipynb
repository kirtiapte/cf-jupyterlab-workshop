{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b98406c-0f47-46bd-aa9c-2138e27e909a",
   "metadata": {},
   "source": [
    "## LangChain with Simple Chain Pattern\n",
    "This example is setting up a LangChain example that connects to a custom OpenAI-compatible large language model (LLM) endpoint using credentials from the environment, then prompts it to suggest a provide a 5 lines of overview of \"VMware Tanzu Hub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c2101-053f-4a53-951b-c87f694f6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory for the project\n",
    "%cd /home/vcap/app/cf-jupyterlab-samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27b902-b872-4018-ab5c-1daac03aaae3",
   "metadata": {},
   "source": [
    "### Step 1: Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc1810-b5d7-4970-8b76-86c0e5e9ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import requests\n",
    "import json\n",
    "import httpx\n",
    "import warnings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tanzu_utils import CFGenAIService\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c641b",
   "metadata": {},
   "source": [
    "### Step 2: Set up the OpenAI API credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ffb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your service details replace name with your Gen AI service.  Gen AI service is bound to the app\n",
    "chat_service = CFGenAIService(\"tanzu-gpt-oss-120b\")\n",
    "\n",
    "# List available models\n",
    "models = chat_service.list_models()\n",
    "for m in models:\n",
    "    print(f\"- {m['name']} (capabilities: {', '.join(m['capabilities'])})\")\n",
    "\n",
    "# construct chat_credentials\n",
    "chat_credentials = {\n",
    "    \"api_base\": chat_service.api_base + \"/openai/v1\",\n",
    "    \"api_key\": chat_service.api_key,\n",
    "    \"model_name\": models[0][\"name\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae906b",
   "metadata": {},
   "source": [
    "### Step 3: Initialize the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. HTTP client (optional but recommended for custom config)\n",
    "httpx_client = httpx.Client(verify=False)  # verify=False if your endpoint needs --insecure\n",
    "\n",
    "# 3. Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.9,\n",
    "    model=chat_credentials[\"model_name\"],   # model name from CF service\n",
    "    base_url=chat_credentials[\"api_base\"],  # OpenAI-compatible endpoint\n",
    "    api_key=chat_credentials[\"api_key\"],    # Bearer token\n",
    "    http_client=httpx_client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3832a",
   "metadata": {},
   "source": [
    "### Step 4: Create a prompt template, create a chain, and run the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Provide a concise 5-line overview of {topic}.\n",
    "    Focus on its purpose, key capabilities, core components,\n",
    "    and how it integrates within the VMware Tanzu ecosystem.\n",
    "    Write in a clear, professional tone suitable for a technical summary.\"\"\"\n",
    ")\n",
    "# Create the chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Define the topic\n",
    "topic = \"VMware Tanzu Hub\"\n",
    "\n",
    "# Run the chain\n",
    "response = chain.run(topic)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
